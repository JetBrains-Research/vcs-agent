{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-21T09:35:08.278960Z",
     "start_time": "2024-06-21T09:35:07.775473Z"
    }
   },
   "source": [
    "from git import Repo, GitCommandError\n",
    "\n",
    "import pandas as pd\n",
    "import os"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T09:35:08.283631Z",
     "start_time": "2024-06-21T09:35:08.280475Z"
    }
   },
   "cell_type": "code",
   "source": [
    "path_to_data = os.path.join(\"C:\\\\Users\\\\tobias.lindenbauer\\\\PycharmProjects\\\\vcs-actions-agent\\\\\", 'data')\n",
    "path_to_repositories = os.path.join(\"C:\\\\Users\\\\tobias.lindenbauer\\\\PycharmProjects\\\\vcs-actions-agent\\\\\", 'repos')"
   ],
   "id": "2aba1407b79b1c26",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Qualitative analysis of metadata",
   "id": "53db4f1de9724ed7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Python",
   "id": "65b430f5e227323a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T09:35:23.404088Z",
     "start_time": "2024-06-21T09:35:23.100433Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1. Read in repositories from CSV\n",
    "python_repositories_metadata = pd.read_csv(os.path.join(path_to_data, 'python_repos.csv'))"
   ],
   "id": "a443e48a4bdc8a38",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T09:16:06.381013Z",
     "start_time": "2024-06-20T09:16:06.376278Z"
    }
   },
   "cell_type": "code",
   "source": "len(python_repositories_metadata)",
   "id": "97e28d88322b4ae",
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's take a look at the distribution of relevant numeric columns to get an overview of the dataset.",
   "id": "c64c4c509709898f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T09:16:10.941277Z",
     "start_time": "2024-06-20T09:16:10.914047Z"
    }
   },
   "cell_type": "code",
   "source": "python_repositories_metadata",
   "id": "adc84287808a5f7b",
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T09:29:07.002100Z",
     "start_time": "2024-05-31T09:29:06.979545Z"
    }
   },
   "cell_type": "code",
   "source": "python_repositories_metadata[['branches', 'releases', 'forks', 'watchers', 'contributors', 'codeLines']].describe()",
   "id": "a0e277a05a5c21f4",
   "execution_count": 13,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "All repositories include more than one branch. Most include some forks. Curiously, we note that `min(codeLines) = 1`. Looking at the mean and 25% quartile though, we see that overall the repos seem to be in a good shape.",
   "id": "de4b08efe10481e5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T09:22:53.856115Z",
     "start_time": "2024-05-31T09:22:53.842902Z"
    }
   },
   "cell_type": "code",
   "source": "python_repositories_metadata[python_repositories_metadata.codeLines < 2]",
   "id": "505fa5c2d5931752",
   "execution_count": 6,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T07:12:26.013550Z",
     "start_time": "2024-06-13T07:12:25.993004Z"
    }
   },
   "cell_type": "code",
   "source": "pd.to_datetime(python_repositories_metadata.updatedAt).describe()",
   "id": "5349483017609eba",
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T09:29:30.525427Z",
     "start_time": "2024-05-31T09:29:30.512131Z"
    }
   },
   "cell_type": "code",
   "source": "pd.to_datetime(python_repositories_metadata.createdAt).describe()",
   "id": "192e022fdf1da8a2",
   "execution_count": 14,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Java",
   "id": "27ed9c2582717537"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T09:39:15.761031Z",
     "start_time": "2024-05-31T09:39:15.569674Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1. Read in repositories from CSV\n",
    "java_repositories_metadata = pd.read_csv(os.path.join(path_to_data, 'java_repos.csv'))"
   ],
   "id": "3a9947b417f3c607",
   "execution_count": 16,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T09:39:16.481690Z",
     "start_time": "2024-05-31T09:39:16.476432Z"
    }
   },
   "cell_type": "code",
   "source": "len(java_repositories_metadata)",
   "id": "2d549245dd847bb1",
   "execution_count": 17,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T09:39:18.432644Z",
     "start_time": "2024-05-31T09:39:18.415339Z"
    }
   },
   "cell_type": "code",
   "source": "java_repositories_metadata[['branches', 'releases', 'forks', 'watchers', 'contributors', 'codeLines']].describe()",
   "id": "938f44e9d0f3eaf4",
   "execution_count": 18,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Most have been forked. Again, we note that `min(codeLines) = 2`. Looking at the mean and 25% quartile though, we see that overall the repos seem to be in a good shape.",
   "id": "9817450c9d277a43"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T09:40:19.207313Z",
     "start_time": "2024-05-31T09:40:19.195283Z"
    }
   },
   "cell_type": "code",
   "source": "pd.to_datetime(java_repositories_metadata.updatedAt).describe()",
   "id": "7909ea7e30e2052c",
   "execution_count": 19,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T09:40:20.209842Z",
     "start_time": "2024-05-31T09:40:20.197436Z"
    }
   },
   "cell_type": "code",
   "source": "pd.to_datetime(java_repositories_metadata.createdAt).describe()",
   "id": "73093bbed22c8d9e",
   "execution_count": 20,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Kotlin",
   "id": "3b18b3bd34cf6c0b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T09:41:09.763613Z",
     "start_time": "2024-05-31T09:41:09.711126Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1. Read in repositories from CSV\n",
    "kotlin_repositories_metadata = pd.read_csv(os.path.join(path_to_data, 'kotlin_repos.csv'))"
   ],
   "id": "dc5301e9b8c0601d",
   "execution_count": 21,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T09:41:10.060988Z",
     "start_time": "2024-05-31T09:41:10.056223Z"
    }
   },
   "cell_type": "code",
   "source": "len(kotlin_repositories_metadata)",
   "id": "fff5d97a0addd7fe",
   "execution_count": 22,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T09:41:10.642970Z",
     "start_time": "2024-05-31T09:41:10.625408Z"
    }
   },
   "cell_type": "code",
   "source": "kotlin_repositories_metadata[['branches', 'releases', 'forks', 'watchers', 'contributors', 'codeLines']].describe()",
   "id": "ea41248746de70fe",
   "execution_count": 23,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Most have been forked. Again, we note that `min(codeLines) = 1`. Looking at the mean and 25% quartile though, we see that overall the repos seem to be in a good shape. For Kotlin, we note that the number of contributors and branches seems lower in general.",
   "id": "e5af7d06c151e3cc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T09:41:11.917345Z",
     "start_time": "2024-05-31T09:41:11.907887Z"
    }
   },
   "cell_type": "code",
   "source": "pd.to_datetime(kotlin_repositories_metadata.updatedAt).describe()",
   "id": "b574a4ba193693a9",
   "execution_count": 24,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T09:41:12.635464Z",
     "start_time": "2024-05-31T09:41:12.625510Z"
    }
   },
   "cell_type": "code",
   "source": "pd.to_datetime(kotlin_repositories_metadata.createdAt).describe()",
   "id": "98e108935223dd4f",
   "execution_count": 25,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Development of git history traversal and quantitative analysis of repositories",
   "id": "5ad58289f66a291a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Determine ratio of branches to files",
   "id": "c5cb822ae05d048"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T09:30:59.788062Z",
     "start_time": "2024-06-21T09:30:59.784162Z"
    }
   },
   "cell_type": "code",
   "source": "import re ",
   "id": "5ad7f9e2cb43ac70",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T09:35:26.772103Z",
     "start_time": "2024-06-21T09:35:26.722562Z"
    }
   },
   "cell_type": "code",
   "source": [
    "repo_instance = None\n",
    "repository_metadata = python_repositories_metadata.iloc[1]\n",
    "repository_path = os.path.join(path_to_repositories, \"__\".join(repository_metadata[\"name\"].split(\"/\")))\n",
    "try:\n",
    "    repo_instance = Repo.clone_from(f'https://github.com/{repository_metadata[\"name\"]}.git',\n",
    "                                f'{repository_path}')\n",
    "except GitCommandError as e:\n",
    "    # If already exists, create Repo instance of it\n",
    "    if 'already exists' in e.stderr:\n",
    "        print('Repository already exists, using local directory instead of cloning.')\n",
    "        repo_instance = Repo(repository_path)"
   ],
   "id": "5a47574b94f37c0e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repository already exists, using local directory instead of cloning.\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T09:36:21.718397Z",
     "start_time": "2024-06-21T09:36:21.712547Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from src.repository_data_scraper import RepositoryDataScraper\n",
    "from src.programming_language import ProgrammingLanguage\n",
    "repo_scraper = RepositoryDataScraper(repository=repo_instance, sliding_window_size=2,\n",
    "                                         language_to_scrape_for=ProgrammingLanguage.TEXT,\n",
    "                                         repository_path=repository_path)"
   ],
   "id": "4690c778bc320919",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T09:40:55.879308Z",
     "start_time": "2024-06-21T09:37:58.872884Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%timeit -n 3\n",
    "repo_scraper.scrape()"
   ],
   "id": "541cccebe8f5697",
   "outputs": [
    {
     "ename": "GitCommandError",
     "evalue": "Cmd('git') failed due to: exit code(128)\n  cmdline: git blame --incremental detected-amazon-mws-auth-token.txt\n  stderr: 'fatal: no such path 'detected-amazon-mws-auth-token.txt' in HEAD'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mGitCommandError\u001B[0m                           Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[12], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mget_ipython\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_cell_magic\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtimeit\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m-n 3\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mrepo_scraper.scrape()\u001B[39;49m\u001B[38;5;130;43;01m\\n\u001B[39;49;00m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\vcs-actions-agent\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:2541\u001B[0m, in \u001B[0;36mInteractiveShell.run_cell_magic\u001B[1;34m(self, magic_name, line, cell)\u001B[0m\n\u001B[0;32m   2539\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbuiltin_trap:\n\u001B[0;32m   2540\u001B[0m     args \u001B[38;5;241m=\u001B[39m (magic_arg_s, cell)\n\u001B[1;32m-> 2541\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2543\u001B[0m \u001B[38;5;66;03m# The code below prevents the output from being displayed\u001B[39;00m\n\u001B[0;32m   2544\u001B[0m \u001B[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001B[39;00m\n\u001B[0;32m   2545\u001B[0m \u001B[38;5;66;03m# when the last Python token in the expression is a ';'.\u001B[39;00m\n\u001B[0;32m   2546\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(fn, magic\u001B[38;5;241m.\u001B[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001B[38;5;28;01mFalse\u001B[39;00m):\n",
      "File \u001B[1;32m~\\PycharmProjects\\vcs-actions-agent\\venv\\Lib\\site-packages\\IPython\\core\\magics\\execution.py:1189\u001B[0m, in \u001B[0;36mExecutionMagics.timeit\u001B[1;34m(self, line, cell, local_ns)\u001B[0m\n\u001B[0;32m   1186\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m time_number \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.2\u001B[39m:\n\u001B[0;32m   1187\u001B[0m             \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[1;32m-> 1189\u001B[0m all_runs \u001B[38;5;241m=\u001B[39m \u001B[43mtimer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrepeat\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrepeat\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnumber\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1190\u001B[0m best \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mmin\u001B[39m(all_runs) \u001B[38;5;241m/\u001B[39m number\n\u001B[0;32m   1191\u001B[0m worst \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mmax\u001B[39m(all_runs) \u001B[38;5;241m/\u001B[39m number\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\timeit.py:208\u001B[0m, in \u001B[0;36mTimer.repeat\u001B[1;34m(self, repeat, number)\u001B[0m\n\u001B[0;32m    206\u001B[0m r \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m    207\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(repeat):\n\u001B[1;32m--> 208\u001B[0m     t \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtimeit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnumber\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    209\u001B[0m     r\u001B[38;5;241m.\u001B[39mappend(t)\n\u001B[0;32m    210\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m r\n",
      "File \u001B[1;32m~\\PycharmProjects\\vcs-actions-agent\\venv\\Lib\\site-packages\\IPython\\core\\magics\\execution.py:173\u001B[0m, in \u001B[0;36mTimer.timeit\u001B[1;34m(self, number)\u001B[0m\n\u001B[0;32m    171\u001B[0m gc\u001B[38;5;241m.\u001B[39mdisable()\n\u001B[0;32m    172\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 173\u001B[0m     timing \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minner\u001B[49m\u001B[43m(\u001B[49m\u001B[43mit\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtimer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    174\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    175\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m gcold:\n",
      "File \u001B[1;32m<magic-timeit>:1\u001B[0m, in \u001B[0;36minner\u001B[1;34m(_it, _timer)\u001B[0m\n",
      "File \u001B[1;32m~\\PycharmProjects\\vcs-actions-agent\\src\\repository_data_scraper.py:68\u001B[0m, in \u001B[0;36mRepositoryDataScraper.scrape\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mscrape\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m     67\u001B[0m     commits \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscrape_commit_based_metadata()\n\u001B[1;32m---> 68\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscrape_file_commit_grams\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcommits\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\vcs-actions-agent\\src\\repository_data_scraper.py:79\u001B[0m, in \u001B[0;36mRepositoryDataScraper.scrape_file_commit_grams\u001B[1;34m(self, commits)\u001B[0m\n\u001B[0;32m     76\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlanguage_to_scrape_for\u001B[38;5;241m.\u001B[39mvalue \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m file:\n\u001B[0;32m     77\u001B[0m     \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[1;32m---> 79\u001B[0m raw_blame \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_raw_git_blame_for\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     80\u001B[0m file_commit_history \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparse(raw_blame)\n\u001B[0;32m     81\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, commit_hash \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(file_commit_history):\n\u001B[0;32m     82\u001B[0m     \u001B[38;5;66;03m# Note: This traverses git rev-list until commit_hash\u001B[39;00m\n\u001B[0;32m     83\u001B[0m     \u001B[38;5;66;03m#   Could hinder performance if we access commits randomly\u001B[39;00m\n\u001B[0;32m     84\u001B[0m     \u001B[38;5;66;03m#   Store commits in Hashmap ie dict?\u001B[39;00m\n",
      "File \u001B[1;32m~\\PycharmProjects\\vcs-actions-agent\\src\\repository_data_scraper.py:107\u001B[0m, in \u001B[0;36mRepositoryDataScraper.get_raw_git_blame_for\u001B[1;34m(self, file)\u001B[0m\n\u001B[0;32m    106\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_raw_git_blame_for\u001B[39m(\u001B[38;5;28mself\u001B[39m, file):\n\u001B[1;32m--> 107\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrepository\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgit\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mblame\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m--incremental\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfile\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\vcs-actions-agent\\venv\\Lib\\site-packages\\git\\cmd.py:986\u001B[0m, in \u001B[0;36mGit.__getattr__.<locals>.<lambda>\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    984\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m name\u001B[38;5;241m.\u001B[39mstartswith(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m    985\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__getattribute__\u001B[39m(name)\n\u001B[1;32m--> 986\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mlambda\u001B[39;00m \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_process\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\vcs-actions-agent\\venv\\Lib\\site-packages\\git\\cmd.py:1598\u001B[0m, in \u001B[0;36mGit._call_process\u001B[1;34m(self, method, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1595\u001B[0m call\u001B[38;5;241m.\u001B[39mappend(dashify(method))\n\u001B[0;32m   1596\u001B[0m call\u001B[38;5;241m.\u001B[39mextend(args_list)\n\u001B[1;32m-> 1598\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcall\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mexec_kwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\vcs-actions-agent\\venv\\Lib\\site-packages\\git\\cmd.py:1388\u001B[0m, in \u001B[0;36mGit.execute\u001B[1;34m(self, command, istream, with_extended_output, with_exceptions, as_process, output_stream, stdout_as_string, kill_after_timeout, with_stdout, universal_newlines, shell, env, max_chunk_size, strip_newline_in_stdout, **subprocess_kwargs)\u001B[0m\n\u001B[0;32m   1385\u001B[0m \u001B[38;5;66;03m# END handle debug printing\u001B[39;00m\n\u001B[0;32m   1387\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m with_exceptions \u001B[38;5;129;01mand\u001B[39;00m status \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m-> 1388\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m GitCommandError(redacted_command, status, stderr_value, stdout_value)\n\u001B[0;32m   1390\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(stdout_value, \u001B[38;5;28mbytes\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m stdout_as_string:  \u001B[38;5;66;03m# Could also be output_stream.\u001B[39;00m\n\u001B[0;32m   1391\u001B[0m     stdout_value \u001B[38;5;241m=\u001B[39m safe_decode(stdout_value)\n",
      "\u001B[1;31mGitCommandError\u001B[0m: Cmd('git') failed due to: exit code(128)\n  cmdline: git blame --incremental detected-amazon-mws-auth-token.txt\n  stderr: 'fatal: no such path 'detected-amazon-mws-auth-token.txt' in HEAD'"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T09:59:21.680164Z",
     "start_time": "2024-06-20T09:57:17.548750Z"
    }
   },
   "cell_type": "code",
   "source": [
    "repositories_statistics = pd.DataFrame()\n",
    "\n",
    "for i, repository_metadata in python_repositories_metadata.iloc[:15].iterrows():\n",
    "    repo_instance = None\n",
    "    repository_path = os.path.join(path_to_repositories, \"__\".join(repository_metadata[\"name\"].split(\"/\")))\n",
    "    try:\n",
    "        repo_instance = Repo.clone_from(f'https://github.com/{repository_metadata[\"name\"]}.git',\n",
    "                                    f'{repository_path}')\n",
    "    except GitCommandError as e:\n",
    "        # If already exists, create Repo instance of it\n",
    "        if 'already exists' in e.stderr:\n",
    "            print('Repository already exists, using local directory instead of cloning.')\n",
    "            repo_instance = Repo(repository_path)\n",
    "            \n",
    "    if repo_instance is None:\n",
    "        continue\n",
    "\n",
    "    os.chdir(os.path.join(path_to_data, repository_path))\n",
    "\n",
    "    repositories_statistics.loc[i, 'branches'] = len(repo_instance.refs)\n",
    "    \n",
    "    num_python_files = 0\n",
    "    num_total_files = 0\n",
    "    for directory,subdirs,files in os.walk(repository_path):\n",
    "        if re.match('.*(\\\\\\\\|\\/)\\..*', directory):\n",
    "            continue # Skip hidden folders\n",
    "        \n",
    "        python_files = [f for f in files if '.py' in f]\n",
    "        total_files = [f for f in files if re.match('^[^\\.].*\\..*$', f)] # skip hidden files and files without file ending\n",
    "        \n",
    "        num_python_files += len(python_files)\n",
    "        num_total_files += len(total_files)\n",
    "\n",
    "    repositories_statistics.loc[i, 'python_files'] = num_python_files\n",
    "    repositories_statistics.loc[i, 'total_files'] = num_total_files"
   ],
   "id": "90e79c7d8f6d06db",
   "execution_count": 21,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T10:19:07.273785Z",
     "start_time": "2024-06-20T10:19:07.267215Z"
    }
   },
   "cell_type": "code",
   "source": "(repositories_statistics.total_files / repositories_statistics.branches).sum() / 10",
   "id": "3c1e4c3abd291cf2",
   "execution_count": 25,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Code experimentation\n",
    "Note that this implementation is somewhat naive and disregards the fact that a sliding window could capture results beyond the branching point of a branch (ie the commit where it was created) if its child commits in another branch also modify the same file, for example. If we need more data, implementing this general case, could be one way to move forward."
   ],
   "id": "bc2429bc66c41f5d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T14:41:58.415777Z",
     "start_time": "2024-06-13T14:41:52.292151Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 2. Generate a Repo instance for it\n",
    "repository_metadata = python_repositories_metadata.iloc[2]\n",
    "repository_path = os.path.join(path_to_repositories, \"__\".join(repository_metadata[\"name\"].split(\"/\")))\n",
    "repo_instance = Repo.clone_from(f'https://github.com/{repository_metadata[\"name\"]}.git', f'{repository_path}')\n",
    "\n",
    "os.chdir(os.path.join(path_to_data, repository_path))\n",
    "\n",
    "#   a. Run analytics operations to extract relevant metrics for overall data\n",
    "\n",
    "# 3. Print overview"
   ],
   "id": "4d11e3e784b6e32d",
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T14:41:58.424300Z",
     "start_time": "2024-06-13T14:41:58.415777Z"
    }
   },
   "cell_type": "code",
   "source": [
    "repo_instance = Repo(os.path.join(path_to_repositories, 'feast-dev__feast'))\n",
    "os.chdir(os.path.join(path_to_repositories, 'feast-dev__feast'))\n",
    "os.getcwd()"
   ],
   "id": "1614afb2394ca845",
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Find merge commits",
   "id": "48c30dd400efc3a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T08:58:53.317058Z",
     "start_time": "2024-06-07T08:58:53.197043Z"
    }
   },
   "cell_type": "code",
   "source": "repo_instance.iter_commits().__next__().message",
   "id": "3fc2fbec3e01825c",
   "execution_count": 8,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T08:58:53.668565Z",
     "start_time": "2024-06-07T08:58:53.589471Z"
    }
   },
   "cell_type": "code",
   "source": "len([commit.message for commit in repo_instance.iter_commits(merges=True)])",
   "id": "56554f86611cd20b",
   "execution_count": 9,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Find sequential commits modifying the same file",
   "id": "26f8e061082404bc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T14:51:17.781851Z",
     "start_time": "2024-06-20T14:51:17.773333Z"
    }
   },
   "cell_type": "code",
   "source": [
    "demo_repo = Repo(os.path.join(path_to_repositories, 'demo-repo'))\n",
    "os.chdir(os.path.join(path_to_repositories, 'demo-repo'))\n",
    "os.getcwd()"
   ],
   "id": "7464a7012cc90995",
   "execution_count": 50,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T14:53:20.918191Z",
     "start_time": "2024-06-20T14:53:20.867703Z"
    }
   },
   "cell_type": "code",
   "source": "demo_repo.git.blame(r'-p', 'document.txt')",
   "id": "856bf9c5e908f747",
   "execution_count": 56,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Get all available branches and set up iteration\n",
    "\n",
    "We will iterate over all branches to generate the metrics with which we want to evaluate the dataset and to find the entry points for dataset creation."
   ],
   "id": "8656eda49e5dfd83"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Get all branches, including remotes, so that we can then check them out and iterate over their commits. Since `branches` contains the raw output of git to stdout, we need to clean it before proceeding.",
   "id": "45db0e5c168df2af"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T14:50:47.917474Z",
     "start_time": "2024-06-13T14:50:47.875479Z"
    }
   },
   "cell_type": "code",
   "source": [
    "branches = pd.Series(repo_instance.git.branch('-a').split('\\n'), name='branch_names')\n",
    "print(len(branches))\n",
    "# Branches will initially just be remote, to check them out and pull them we clean them by removing:\n",
    "#   the remote prefix\n",
    "#   any whitespace\n",
    "#   literal line breaks\n",
    "#   the asterisk denoting the current branch\n",
    "branches = branches.str.replace(r'(remotes/origin/|\\s*|\\n|\\*)', '', regex=True)\n",
    "# Then we remove the branch pointed at by the head (this is just METADATA and the branch would be duplicated otherwise)\n",
    "# E.g. HEAD->master and master, we want to keep master\n",
    "branches = branches[~branches.str.contains('HEAD->')]"
   ],
   "id": "3d6fb9ec3c277c0a",
   "execution_count": 34,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T14:57:03.365173Z",
     "start_time": "2024-06-13T14:56:40.871608Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for branch in branches:\n",
    "    repo_instance.git.checkout(branch)"
   ],
   "id": "5e388b78972208d6",
   "execution_count": 47,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "fetches = repo_instance.remotes.origin.fetch()\n",
    "fetches[2].remote_ref_path"
   ],
   "id": "9b702f695fa4da99",
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T14:58:26.479202Z",
     "start_time": "2024-06-13T14:58:26.366682Z"
    }
   },
   "cell_type": "code",
   "source": "len([c.hexsha for c in repo_instance.iter_commits(all=True)])",
   "id": "fc5a369b9e723831",
   "execution_count": 51,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T14:57:31.114063Z",
     "start_time": "2024-06-13T14:57:31.106997Z"
    }
   },
   "cell_type": "code",
   "source": "repo_instance.commit",
   "id": "ed33617023a2c9a3",
   "execution_count": 49,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Next, we need to ensure to continue to the next branch, once we reached its branching point or root node. We do not want to iterate over the entire graph (meaning all children including those of the branch from which this branch originated) for every branch.",
   "id": "64d807fc8b9077ac"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T14:58:56.655982Z",
     "start_time": "2024-06-13T14:58:56.652565Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# This even solves the issue of the generalization\n",
    "def find_branches_containing_commit(commit_sha, repo):\n",
    "    # Find branches containing the commit\n",
    "    branches_containing_commit = []\n",
    "    for branch in repo.branches:\n",
    "        branch_commit = repo.commit(branch)\n",
    "        try:\n",
    "            # Check if commit is reachable from the branch\n",
    "            # Not sure if this is even correct\n",
    "            # Ancestor is towards newer commits\n",
    "            if repo.is_ancestor(commit_sha, branch_commit):\n",
    "                branches_containing_commit.append(branch)\n",
    "        except GitCommandError as e:\n",
    "            print(f\"Error while processing branch {branch}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    return branches_containing_commit"
   ],
   "id": "950d024fdeee79db",
   "execution_count": 52,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T14:51:36.161114Z",
     "start_time": "2024-06-13T14:51:36.157266Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def update_accumulator_with(file_state: dict, file_to_remove: str, branch: str):\n",
    "    if file_state['times_seen_consecutively'] >= sliding_window_size:\n",
    "        accumulator.append({'file': file_to_remove, 'branch': branch, 'first_commit': file_state['first_commit'], 'last_commit': file_state['last_commit'], 'times_seen_consecutively': file_state['times_seen_consecutively']})"
   ],
   "id": "1ec8f4ded0b262f6",
   "execution_count": 38,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T15:02:36.556241Z",
     "start_time": "2024-06-13T15:02:36.464309Z"
    }
   },
   "cell_type": "code",
   "source": "snippet_commits = list(repo_instance.iter_commits(all=True))[:25]",
   "id": "74f51fd4541b5406",
   "execution_count": 54,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T15:04:08.044250Z",
     "start_time": "2024-06-13T15:02:38.520731Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sliding_window_size = 2\n",
    "\n",
    "# Maintains a state for each file currently in scope\n",
    "# Each scope is defined by the overlap size n, if we do not see the file again after n steps we remove it from the state\n",
    "state = {} \n",
    "\n",
    "# Accumulates file-commit grams\n",
    "# If we detect a series of n consecutive modifications of the same file we append a dict to this list.\n",
    "# Each dict contains: The associated file (relative path from working directory), first commit for this file-commit gram, last commit for this file-commit gram\n",
    "# and how many times the file was seen consecutively (length of the file-commit gram)\n",
    "# Note that the change_types that are valid are M, MM, A. All other change types are ignored (because the file wasn't modified).\n",
    "accumulator = []\n",
    "\n",
    "valid_change_types = ['A', 'M', 'MM']\n",
    "for commit in snippet_commits: # We will visit each commit exactly once\n",
    "    branches_with_commit = find_branches_containing_commit(commit.hexsha, repo_instance)\n",
    "    \n",
    "    changes_in_commit = repo_instance.git.show(commit, name_status=True, format='oneline').split('\\n')\n",
    "    changes_in_commit = changes_in_commit[1:] # remove commit hash and message\n",
    "    changes_in_commit = [change for change in changes_in_commit if change] # filter empty lines\n",
    "    \n",
    "    # If any change in this commit is a valid change, we want to update the state\n",
    "    # This is important, because operations on the state, when we dont want to perform them\n",
    "    # can lead to flaky behaviour. This is needed for the cleanup phase that removes stale files.\n",
    "    # Implicitly ensures that we len(changes_in_commit) > 0, because otherwise we would not iterate at all\n",
    "    should_process_commit = False\n",
    "    for change in changes_in_commit:\n",
    "        change_type = change.split('\\t')[0]\n",
    "        should_process_commit = change_type in valid_change_types\n",
    "        if should_process_commit:\n",
    "            break\n",
    "    \n",
    "    if should_process_commit:\n",
    "        # Commit has changes\n",
    "        affected_files = []\n",
    "        \n",
    "        # Parse changes\n",
    "        # Do we need to update the state of this particular file?\n",
    "        for change_in_commit in changes_in_commit:\n",
    "            changes_to_unpack = change_in_commit.split('\\t')\n",
    "            if changes_to_unpack[0] not in valid_change_types:\n",
    "                continue\n",
    "                \n",
    "            change_type, file = changes_to_unpack\n",
    "            affected_files.append(file)        \n",
    "            \n",
    "            # Update the file state for every branch with this commit\n",
    "            # Otherwise ignore this commit (dont update state)\n",
    "            for branch in branches_with_commit:\n",
    "                # We should maintain a state for this branch, ensure that we are\n",
    "                if branch  not in state:\n",
    "                    state[branch] = {}\n",
    "                \n",
    "                if file in state[branch]:\n",
    "                    # We are maintaining a state for this file on this branch\n",
    "                    state[branch][file]['times_seen_consecutively'] = state[branch][file]['times_seen_consecutively'] + 1\n",
    "                \n",
    "                    if state[branch][file]['times_seen_consecutively'] >= sliding_window_size:\n",
    "                        state[branch][file]['last_commit'] = commit.hexsha\n",
    "                else:\n",
    "                    # We are not currently maintaining a state for this file in this branch, but have detected it\n",
    "                    # Need to set up the state dict\n",
    "                    state[branch][file] = {'first_commit': commit.hexsha, 'last_commit': commit.hexsha, 'times_seen_consecutively': 1}\n",
    "                    \n",
    "            # We updated (Add, Update) one file of the commit for all affected branches at this point\n",
    "        # (Add, Update) ALL files of the commit for all affected branches\n",
    "        # Now we only need to remove stale file states (files that were not found in the commit)\n",
    "        for branch in branches_with_commit:\n",
    "            # Only do this for branches affected by the commit\n",
    "            new_state = {}\n",
    "            for file in state[branch]:\n",
    "                if file in affected_files:\n",
    "                    new_state[file] = state[branch][file]\n",
    "                else:\n",
    "                    update_accumulator_with(state[branch][file], file, branch)\n",
    "        \n",
    "            state[branch] = new_state\n",
    "\n",
    "accumulator"
   ],
   "id": "742d021eda9ef07f",
   "execution_count": 55,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T12:59:16.249670Z",
     "start_time": "2024-06-07T12:59:16.184897Z"
    }
   },
   "cell_type": "code",
   "source": [
    "commit = demo_repo.commit('aeeab817a1bd7d146fc7596546e0c98a0ec94dbc')\n",
    "commit.stats.files"
   ],
   "id": "edff5795651840b3",
   "execution_count": 93,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T11:35:52.472224Z",
     "start_time": "2024-05-24T11:35:52.407232Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sliding_window_state = []\n",
    "result = []\n",
    "\n",
    "commit_history = [commit for commit in demo_repo.iter_commits(all=True)]\n",
    "\n",
    "def find_files_modified_within_consecutive_commits(commits_to_process, window_size, sliding_window_state):\n",
    "    while commits_to_process:\n",
    "        commit = commits_to_process.pop()\n",
    "        \n",
    "        if commit_children[commit.hexsha]['children_count'] == 1 and len(commit.parents) == 1:\n",
    "            # This is an ordinary commit\n",
    "            # Stay in this recursion and continue iterating\n",
    "            pass\n",
    "        elif commit_children[commit.hexsha]['children_count'] >= 2:\n",
    "            # This commit is the starting point of at least one other branch\n",
    "            result.append(find_files_modified_within_consecutive_commits(commits_to_process, window_size, sliding_window_state))\n",
    "        \n",
    "    \n",
    "\n",
    "    "
   ],
   "id": "3a41d631e9a431df",
   "execution_count": 107,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T11:35:52.778005Z",
     "start_time": "2024-05-24T11:35:52.772925Z"
    }
   },
   "cell_type": "code",
   "source": "commit_history.pop().message",
   "id": "2bdf5a42e64bc942",
   "execution_count": 108,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Currently not used just for docs of what I tried already",
   "id": "b763547c3a635a7c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T14:44:05.221443Z",
     "start_time": "2024-05-23T14:44:05.217630Z"
    }
   },
   "cell_type": "code",
   "source": "remote_refs = repo_instance.remote().refs",
   "id": "d4d376bddc4bee6e",
   "execution_count": 81,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T14:54:27.301307Z",
     "start_time": "2024-05-23T14:54:26.640206Z"
    }
   },
   "cell_type": "code",
   "source": [
    "remote = repo_instance.remote()\n",
    "\n",
    "remote_ref = remote_refs[1]\n",
    "remote.fetch(remote_ref.remote_head)\n",
    "repo_instance.branches"
   ],
   "id": "5138dd4be701d163",
   "execution_count": 100,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T14:33:34.567315Z",
     "start_time": "2024-05-23T14:33:33.873386Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for remote in repo_instance.remotes:\n",
    "    remote.fetch()"
   ],
   "id": "a065bb3b85f07b2e",
   "execution_count": 72,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": 65,
   "source": [
    "for commit in repo_instance.iter_commits():\n",
    "    print(f\"{commit.hexsha} {commit.summary}\")"
   ],
   "id": "a799df77e60626e1",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
